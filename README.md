# فكرة الكود بشكل عام 

هذا المشروع يستخدم نموذج YOLO للتصنيف لاكتشاف وتصنيف الأجسام في الوقت الحقيقي عبر كاميرا الويب. يقوم البرنامج بالتقاط الإطارات من الفيديو، ثم يمررها من خلال نموذج YOLO لاكتشاف الأجسام وتصنيفها، ثم يعرض النتائج على الشاشة. يتم التوقف عن العمل عندما يضغط المستخدم على 'q'.
# شرح الكود

استيراد المكتبات:

cv2: مكتبة OpenCV التي تساعد في التقاط الإطارات من الكاميرا وعرضها.

YOLO من مكتبة ultralytics: لتحميل النموذج واستخدامه في اكتشاف وتصنيف الأجسام.

تحميل نموذج YOLO:

model = YOLO("yolo11n-cls"): يقوم بتحميل نموذج YOLO المصمم لتصنيف الأجسام.

فتح كاميرا الويب:

cap = cv2.VideoCapture(0): فتح الكاميرا لالتقاط الفيديو من الكاميرا الافتراضية.

حلقة التقاط ومعالجة الفيديو:

في كل مرة، يقوم cap.read() بقراءة الإطار التالي من الفيديو. إذا كانت القراءة ناجحة، يتم إرسال الإطار إلى النموذج للتصنيف باستخدام results = model(frame).

بعد تصنيف الإطار، يتم رسم النتائج على الإطار باستخدام annotated_frame = results[0].plot().

ثم يتم عرض الإطار المضاف إليه التصنيف باستخدام cv2.imshow("YOLO Inference", annotated_frame).

الخروج من البرنامج:

إذا ضغط المستخدم على 'q'، سيتم كسر الحلقة والخروج من التطبيق.

تحرير الموارد:

cap.release(): لإغلاق الكاميرا.

cv2.destroyAllWindows(): لإغلاق جميع النوافذ المفتوحة.
